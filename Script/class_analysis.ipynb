{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model for DLBCL subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python一般\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import scipy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss, roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "import torch\n",
    "import shap\n",
    "\n",
    "import module.utils as utils\n",
    "import module.models as models\n",
    "\n",
    "%precision 4\n",
    "\n",
    "ROOT= \"/\".join(os.getcwd().split(\"/\")[:-1])\n",
    "DIR_LOG = os.path.join(ROOT, \"LOG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data File\n",
    "gmt_path = os.path.join(ROOT, \"data\", \"GSEA\", \"geneset\", \"c2.cp.kegg.v7.3.symbols.gmt\")\n",
    "gml_path = os.path.join(ROOT, \"data\", \"Graphml\", \"kegg.graphml\")\n",
    "ensembl_path = os.path.join(ROOT, \"data\", \"GSEA\", \"geneset\", \"Human_ENSEMBL_Gene_ID_MSigDB.v7.3.chip\")\n",
    "entrez_path = os.path.join(ROOT, \"data\", \"GSEA\", \"geneset\", \"Human_NCBI_Entrez_Gene_ID_MSigDB.v7.2.chip\")\n",
    "expression_path = os.path.join(ROOT, \"data\", \"GSE31312\", \"rma_expression.pickle\")\n",
    "clinical_df_path = os.path.join(ROOT, \"data\", \"GSE31312\", \"clinical.csv\")\n",
    "\n",
    "cv = 5\n",
    "n_seed = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(n_seed)\n",
    "_ = torch.manual_seed(n_seed)\n",
    "\n",
    "overall_scores = {}\n",
    "Y_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for training\n",
    "from module.models import Graph_from_GSEA, Load_Dataset, Graph_Exp_Data\n",
    "# Graphの読み込み(Reactome)\n",
    "path_graphs = Graph_from_GSEA(gmt_path = gmt_path,\n",
    "                              gml_path = gml_path,\n",
    "                              gene_convert_ensembl = ensembl_path,\n",
    "                              gene_convert_entrez  = entrez_path)\n",
    "\n",
    "# Load expression data\n",
    "dataset = Load_Dataset(array_path = expression_path,\n",
    "                   clinical_path = clinical_df_path)\n",
    "\n",
    "# Set label data\n",
    "dataset.Y = pd.DataFrame(dataset.clinicalDf[\"GEP\"].map({\"GCB\":0, \"ABC\":1, np.nan:np.nan}).dropna())\n",
    "\n",
    "# Select genes in KEGG pathways\n",
    "dataset.x_expression = dataset.x_expression.loc[:, np.isin(dataset.x_expression.columns, list(path_graphs.pathways.all_genes))]\n",
    "dataset.x_expression = pd.DataFrame(scipy.stats.zscore(dataset.x_expression, axis=1), \n",
    "                             index=dataset.x_expression.index, \n",
    "                             columns=dataset.x_expression.columns) # 正規化\n",
    "train_idx = dataset.Y.index\n",
    "\n",
    "dgl_dataset = Graph_Exp_Data(x=dataset.x_expression.loc[train_idx, :], \n",
    "                             y=dataset.Y.loc[train_idx], \n",
    "                             graphs = path_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for test dataset\n",
    "expression_path = os.path.join(ROOT, \"data\", \"GSE10846\", \"rma_expression.pickle\")\n",
    "clinical_df_path = os.path.join(ROOT, \"data\", \"GSE10846\", \"clinical.csv\")\n",
    "\n",
    "test_dataset = Load_Dataset(array_path = expression_path,\n",
    "                   clinical_path = clinical_df_path)\n",
    "\n",
    "test_dataset.Y = pd.DataFrame(test_dataset.clinicalDf[\"GEP\"].map({\"GCB\":0, \"ABC\":1, \"UC\": np.nan, np.nan:np.nan}).dropna())\n",
    "\n",
    "test_dataset.x_expression = test_dataset.x_expression.loc[:, np.isin(test_dataset.x_expression.columns, list(path_graphs.pathways.all_genes))]\n",
    "test_dataset.x_expression = pd.DataFrame(scipy.stats.zscore(test_dataset.x_expression, axis=1), \n",
    "                             index=test_dataset.x_expression.index, \n",
    "                             columns=test_dataset.x_expression.columns) # 正規化\n",
    "\n",
    "test_idx = test_dataset.Y.index\n",
    "\n",
    "test_dgl_dataset = Graph_Exp_Data(x=test_dataset.x_expression.loc[test_idx, :], \n",
    "                             y=test_dataset.Y.loc[test_idx], \n",
    "                             graphs = path_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP: Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "X_train = dataset.x_expression.loc[train_idx, :]\n",
    "X_train = torch.from_numpy(X_train.values).float()\n",
    "\n",
    "Y_train = dataset.Y.loc[train_idx, :]\n",
    "Y_train = Y_train.values.reshape(-1)\n",
    "Y_train = torch.from_numpy(Y_train).long()\n",
    "\n",
    "# Test Data\n",
    "X_test = test_dataset.x_expression.loc[test_idx, :]\n",
    "X_test = torch.from_numpy(X_test.values).float()\n",
    "Y_test = test_dataset.Y.loc[test_idx, :]\n",
    "Y_test = Y_test.values.reshape(-1)\n",
    "Y_test = torch.from_numpy(Y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"################################################\")\n",
    "print(\"#                      MLP                     #\")\n",
    "print(\"################################################\")\n",
    "\n",
    "importlib.reload(models)\n",
    "from module.models import MLP_Trainer\n",
    "\n",
    "file_path = os.path.join(DIR_LOG, str(n_seed), \"mlp\")\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "param_grid = {\n",
    "    \"in_dim\": [dataset.x_expression.shape[1]],\n",
    "    \"hidden_dim1\": [1000, 3000],\n",
    "    \"hidden_dim2\": [1000, 3000],\n",
    "    \"hidden_dim3\": [1000],\n",
    "    \"n_class\" : [2],\n",
    "    \"learning_rate\" : [1e-4, 1e-6],\n",
    "    \"n_epoch\": [50],\n",
    "    \"patience\": [5],\n",
    "    \"n_batch\" : [64, 128],\n",
    "    \"dropout\" : [0.2, 0.4, 0.6],\n",
    "         }\n",
    "n_search = 30\n",
    "\n",
    "trainer = MLP_Trainer(path=file_path, device=device)\n",
    "trainer.X_test = X_test\n",
    "trainer.Y_test = Y_test\n",
    "trainer.gridsearch_cv(X_train, Y_train, param_grid, cv=cv, max_n_search=n_search, random_seed=n_seed, testscore=True, score_metrics=\"acc\")\n",
    "trainer.load_bestmodel(load_log=True)\n",
    "pred = trainer.predict(X_test)\n",
    "test_score = trainer.multi_acc(Y_test, pred)\n",
    "print(f\"Test Score: {test_score:.3g}\")\n",
    "overall_scores[\"mlp\"] = np.mean(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from module.models import MLP_Trainer\n",
    "torch.manual_seed(n_seed)\n",
    "variable_name = \"mlp\"\n",
    "file_path = os.path.join(DIR_LOG, str(n_seed), \"mlp\")\n",
    "trainer = MLP_Trainer(path=file_path, device=device)\n",
    "trainer.load_bestmodel(load_log=True)\n",
    "\n",
    "print(\"Training set\")\n",
    "Y_proba = trainer.predict(X_train)\n",
    "fpr, tpr, thres = roc_curve(Y_train, Y_proba[:,1])\n",
    "cutoff = thres[np.argmin(1-tpr+fpr)]\n",
    "Y_pred = [1 if x > cutoff else 0 for x in Y_proba[:, 1]]\n",
    "\n",
    "acc = accuracy_score(Y_train, Y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "scores = precision_recall_fscore_support(Y_train, Y_pred, average=\"binary\")\n",
    "\n",
    "print(f\"Precision: {scores[0]:.3f}\")\n",
    "print(f\"Recall: {scores[1]:.3f}\")\n",
    "print(f\"F1 score: {scores[2]:.3f}\")\n",
    "\n",
    "roc_auc = roc_auc_score(Y_train, Y_proba[:, 1])\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "print(\"Test set\")\n",
    "Y_proba = trainer.predict(X_test)\n",
    "Y_pred = [1 if x > cutoff else 0 for x in Y_proba[:, 1]]\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "scores = precision_recall_fscore_support(Y_test, Y_pred, average=\"binary\")\n",
    "print(f\"Precision: {scores[0]:.3f}\")\n",
    "print(f\"Recall: {scores[1]:.3f}\")\n",
    "print(f\"F1 score: {scores[2]:.3f}\")\n",
    "roc_auc = roc_auc_score(Y_test, Y_proba[:, 1])\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "n_parameters = sum([np.prod(x.shape) for x in trainer.net.parameters()])\n",
    "print(f\"Number of parameters {n_parameters}\")\n",
    "pred = trainer.predict(X_train)\n",
    "Y_scores.append((Y_train, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgl_dataset.mapping_attr()\n",
    "X_train = dgl_dataset.attr.float()\n",
    "Y_train = dgl_dataset.y\n",
    "\n",
    "test_dgl_dataset.mapping_attr()\n",
    "X_test = test_dgl_dataset.attr.float()\n",
    "Y_test = test_dgl_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"################################################\")\n",
    "print(\"#                      GCN                     #\")\n",
    "print(\"################################################\")\n",
    "\n",
    "importlib.reload(models)\n",
    "from module.models import GCN_Trainer\n",
    "\n",
    "file_path = os.path.join(DIR_LOG, str(n_seed), \"gcn\")\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "param_grid = {\n",
    "    \"in_dim\": [1],\n",
    "    \"hidden_dim1\": [0],\n",
    "    \"hidden_dim2\": [0],\n",
    "    \"gcn_dim1\" : [10, 20, 40],\n",
    "    \"gcn_dim2\" : [5, 10, 20],\n",
    "    \"n_class\" : [2],\n",
    "    \"learning_rate\" : [1e-2,1e-4,1e-6],\n",
    "    \"n_epoch\": [50],\n",
    "    \"patience\": [5],\n",
    "    \"n_batch\" : [64, 128],\n",
    "    \"dropout\" : [0.2, 0.4, 0.6],\n",
    "    \"deep_fc\" : [False]\n",
    "         }\n",
    "\n",
    "n_search = 30\n",
    "\n",
    "trainer = GCN_Trainer(dgl_dataset.batched_graph, path=file_path, device=device)\n",
    "trainer.X_test = X_test\n",
    "trainer.Y_test = Y_test\n",
    "trainer.gridsearch_cv(X_train, Y_train, param_grid, cv=5, max_n_search=n_search, random_seed=n_seed, testscore=True, score_metrics=\"acc\")\n",
    "trainer.load_bestmodel(load_log=True)\n",
    "pred = trainer.predict(X_test)\n",
    "test_score = trainer.multi_acc(Y_test, pred)\n",
    "print(f\"Test Score: {test_score:.3g}\")\n",
    "overall_scores[\"gcn\"] = np.mean(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from module.models import GCN_Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, brier_score_loss, roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "torch.manual_seed(n_seed)\n",
    "file_path = os.path.join(DIR_LOG, str(n_seed), \"gcn\")\n",
    "trainer = GCN_Trainer(dgl_dataset.batched_graph, path=file_path, device=device)\n",
    "trainer.load_bestmodel(load_log=True)\n",
    "\n",
    "print(\"Training set\")\n",
    "Y_proba = trainer.predict(X_train)\n",
    "fpr, tpr, thres = roc_curve(Y_train, Y_proba[:,1])\n",
    "cutoff = thres[np.argmin(1-tpr+fpr)]\n",
    "Y_pred = [1 if x > cutoff else 0 for x in Y_proba[:, 1]]\n",
    "\n",
    "acc = accuracy_score(Y_train, Y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "scores = precision_recall_fscore_support(Y_train, Y_pred, average=\"binary\")\n",
    "\n",
    "print(f\"Precision: {scores[0]:.3f}\")\n",
    "print(f\"Recall: {scores[1]:.3f}\")\n",
    "print(f\"F1 score: {scores[2]:.3f}\")\n",
    "\n",
    "roc_auc = roc_auc_score(Y_train, Y_proba[:, 1])\n",
    "#score_dict[\"rocauc\"].append(roc_auc)\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "print(\"Test set\")\n",
    "Y_proba = trainer.predict(X_test)\n",
    "Y_pred = [1 if x > cutoff else 0 for x in Y_proba[:, 1]]\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "scores = precision_recall_fscore_support(Y_test, Y_pred, average=\"binary\")\n",
    "print(f\"Precision: {scores[0]:.3f}\")\n",
    "print(f\"Recall: {scores[1]:.3f}\")\n",
    "print(f\"F1 score: {scores[2]:.3f}\")\n",
    "roc_auc = roc_auc_score(Y_test, Y_proba[:, 1])\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "n_parameters = sum([np.prod(x.shape) for x in trainer.net.parameters()])\n",
    "print(f\"Number of parameters {n_parameters}\")\n",
    "pred = trainer.predict(X_train)\n",
    "Y_scores.append((Y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"################################################\")\n",
    "print(\"#                    GCN-MLP                   #\")\n",
    "print(\"################################################\")\n",
    "\n",
    "importlib.reload(models)\n",
    "from module.models import GCN_Trainer\n",
    "\n",
    "file_path = os.path.join(DIR_LOG, str(n_seed), \"gcn_mlp\")\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "param_grid = {\n",
    "    \"in_dim\": [1],\n",
    "    \"hidden_dim1\": [1000],\n",
    "    \"hidden_dim2\": [1000],\n",
    "    \"gcn_dim1\" : [10, 20, 40],\n",
    "    \"gcn_dim2\" : [5, 10, 20],\n",
    "    \"n_class\" : [2],\n",
    "    \"learning_rate\" : [1e-2,1e-4],\n",
    "    \"n_epoch\": [50],\n",
    "    \"patience\": [5],\n",
    "    \"n_batch\" : [64, 128],\n",
    "    \"dropout\" : [0.2, 0.4, 0.6],\n",
    "    \"deep_fc\" : [True]\n",
    "         }\n",
    "\n",
    "n_search = 30\n",
    "\n",
    "trainer = GCN_Trainer(dgl_dataset.batched_graph, path=file_path, device=device)\n",
    "trainer.X_test = X_test\n",
    "trainer.Y_test = Y_test\n",
    "trainer.gridsearch_cv(X_train, Y_train, param_grid, cv=cv, max_n_search=n_search, random_seed=n_seed, testscore=True, score_metrics=\"acc\")\n",
    "trainer.load_bestmodel(load_log=True)\n",
    "pred = trainer.predict(X_test)\n",
    "test_score = trainer.multi_acc(Y_test, pred)\n",
    "print(f\"Test Score: {test_score:.3g}\")\n",
    "overall_scores[\"gcn_mlp\"] = np.mean(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from module.models import GCN_Trainer\n",
    "torch.manual_seed(n_seed)\n",
    "file_path = os.path.join(DIR_LOG, str(n_seed), \"gcn_mlp\")\n",
    "trainer = GCN_Trainer(dgl_dataset.batched_graph, path=file_path, device=device)\n",
    "trainer.load_bestmodel(load_log=True)\n",
    "\n",
    "print(\"Training set\")\n",
    "Y_proba = trainer.predict(X_train)\n",
    "fpr, tpr, thres = roc_curve(Y_train, Y_proba[:,1])\n",
    "cutoff = thres[np.argmin(1-tpr+fpr)]\n",
    "Y_pred = [1 if x > cutoff else 0 for x in Y_proba[:, 1]]\n",
    "\n",
    "# 評価\n",
    "acc = accuracy_score(Y_train, Y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "scores = precision_recall_fscore_support(Y_train, Y_pred, average=\"binary\")\n",
    "\n",
    "print(f\"Precision: {scores[0]:.3f}\")\n",
    "print(f\"Recall: {scores[1]:.3f}\")\n",
    "print(f\"F1 score: {scores[2]:.3f}\")\n",
    "\n",
    "roc_auc = roc_auc_score(Y_train, Y_proba[:, 1])\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "print(\"Test set\")\n",
    "Y_proba = trainer.predict(X_test)\n",
    "Y_pred = [1 if x > cutoff else 0 for x in Y_proba[:, 1]]\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "scores = precision_recall_fscore_support(Y_test, Y_pred, average=\"binary\")\n",
    "print(f\"Precision: {scores[0]:.3f}\")\n",
    "print(f\"Recall: {scores[1]:.3f}\")\n",
    "print(f\"F1 score: {scores[2]:.3f}\")\n",
    "roc_auc = roc_auc_score(Y_test, Y_proba[:, 1])\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "n_parameters = sum([np.prod(x.shape) for x in trainer.net.parameters()])\n",
    "print(f\"Number of parameters {n_parameters}\")\n",
    "pred = trainer.predict(X_train)\n",
    "Y_scores.append((Y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record scores in dataframe\n",
    "file_path = os.path.join(DIR_LOG, \"overall_scores.csv\")\n",
    "try:\n",
    "    result = pd.read_csv(file_path, index_col=0).to_dict()\n",
    "    if str(n_seed) not in result:\n",
    "        result[str(n_seed)] = {}\n",
    "    result[str(n_seed)].update(overall_scores)\n",
    "except:\n",
    "    result = {str(n_seed): overall_scores}\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calibration plot\n",
    "from sklearn.calibration import calibration_curve\n",
    "fig = plt.figure(1, figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "label_name = [\"mlp\", \"gcn\", \"gcn_mlp\"]\n",
    "\n",
    "i=0\n",
    "labels = Y_test\n",
    "for labels, pred in Y_scores:\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(labels, pred[:,1], n_bins=5)\n",
    "    prob_pos = pred[:, 1]\n",
    "    clf_score = brier_score_loss(labels, prob_pos, pos_label=1)\n",
    "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "             label=f\"{label_name[i]} ({clf_score:.3f})\")\n",
    "    i+=1\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')\n",
    "fig.savefig(os.path.join(DIR_LOG, str(n_seed), \"calibration_plots.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output dataset for GSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcb_idx = dataset.Y.query(f'GEP == 0').index\n",
    "abc_idx = dataset.Y.query(f'GEP == 1').index\n",
    "label_idx = {\"GCB\": gcb_idx, \"ABC\": abc_idx}\n",
    "\n",
    "_ = utils.create_gsea_dataset(dataset.x_expression.T,\n",
    "                          label_idx,\n",
    "                          gene_id_type=\"symbol\",\n",
    "                          filename=\"GSE31312_gep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP on GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(n_seed)\n",
    "file_path = os.path.join(DIR_LOG, str(n_seed), \"gcn\")\n",
    "model_path = os.path.join(file_path, \"model.pth\")\n",
    "\n",
    "trainer = GCN_Trainer(dgl_dataset.batched_graph, path=file_path, device=device)\n",
    "trainer.load_bestmodel(load_log=True)\n",
    "params = trainer.p\n",
    "gcn_out_dim = params[\"gcn_dim2\"]\n",
    "graph_names = dgl_dataset.graph_names\n",
    "n_graph = len(graph_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# SHAP\n",
    "shap.initjs()\n",
    "shap_seed=0\n",
    "\n",
    "gcn_param = {\"g\": trainer.g, \"n_graphs\": n_graph}\n",
    "gcn_net = GCN_classifier(outcome=2, **gcn_param ,**params)\n",
    "gcn_net.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")), strict=False)\n",
    "gcn_net = gcn_net.to(device)\n",
    "\n",
    "explainer_x = dgl_dataset.attr.float().to(device)\n",
    "shap_value_x = dgl_dataset.attr.float().to(device)\n",
    "\n",
    "explainer_whole = shap.GradientExplainer(gcn_net, explainer_x)\n",
    "shap_values_whole = explainer_whole.shap_values(explainer_x[0:100])\n",
    "\n",
    "# Save SHAP data\n",
    "df = pd.DataFrame(shap_values_whole[0], columns = dgl_dataset.columns)\n",
    "df.to_csv(os.path.join(file_path, \"gene_level_shap.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary plot\n",
    "# Load SHAP data\n",
    "df = pd.read_csv(os.path.join(file_path, \"gene_level_shap.csv\"), index_col=0)\n",
    "df.columns = [x.split(\".\")[0] for x in df.columns]\n",
    "\n",
    "df = df.abs().T.groupby(df.columns).sum().T\n",
    "fig = shap.summary_plot(df, feature_names=df.columns, plot_type=\"bar\",\n",
    "                 title = \"Gene-level feature importance\",\n",
    "                 show=False)\n",
    "plt.savefig(os.path.join(file_path, \"shap_gene_level_gcn.png\"))\n",
    "plt.show()\n",
    "df.mean().sort_values(ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.models import GCN_classifier, GCN_classifier_layer1, GCN_classifier_layer2\n",
    "\n",
    "# Extract intermedaite layer\n",
    "shap.initjs()\n",
    "shap_seed=0\n",
    "feature_name = [graph_names[i] for i in range(len(graph_names)) for _ in range(gcn_out_dim)]\n",
    "\n",
    "gcn_param = {\"g\": trainer.g, \"n_graphs\": n_graph}\n",
    "gcn_net_layer1 = GCN_classifier_layer1(outcome=2, **gcn_param ,**params)\n",
    "gcn_net_layer1.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")), strict=False)\n",
    "gcn_net_layer1 = gcn_net_layer1.to(device)\n",
    "gcn_net_layer2 = GCN_classifier_layer2(outcome=2, **gcn_param ,**params)\n",
    "gcn_net_layer2.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")), strict=False)\n",
    "gcn_net_layer2 = gcn_net_layer2.to(device)\n",
    "\n",
    "# Shap\n",
    "sample = np.random.choice(len(dgl_dataset), size=len(dgl_dataset), replace=False)\n",
    "explainer_x = dgl_dataset.attr[sample].float().to(device)\n",
    "shap_value_x = dgl_dataset.attr[sample[0:100]].float().to(device)\n",
    "shap_value_x = dgl_dataset.attr[sample].float().to(device)\n",
    "\n",
    "gcn_net_layer1.eval()\n",
    "with torch.no_grad():\n",
    "    explainer_mid_x = gcn_net_layer1(explainer_x)\n",
    "    shap_mid_x = gcn_net_layer1(shap_value_x)\n",
    "\n",
    "explainer = shap.DeepExplainer(gcn_net_layer2, explainer_mid_x)\n",
    "shap_values = explainer.shap_values(shap_mid_x)\n",
    "\n",
    "# Compute mean absolute shapley values\n",
    "shap_mean = np.abs(shap_values[0]).mean(axis=0)\n",
    "shap_mean = [shap_mean[i*params[\"gcn_dim2\"]:(i+1)*params[\"gcn_dim2\"]].sum() for i in range(n_graph)]\n",
    "\n",
    "# Save Data\n",
    "df = pd.DataFrame(shap_values[0], columns = feature_name)\n",
    "df.to_csv(os.path.join(file_path, \"kegg_shap.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary plot\n",
    "# Load data\n",
    "df = pd.read_csv(os.path.join(file_path, \"kegg_shap.csv\"), index_col=0)\n",
    "df.columns = [x.split(\".\")[0] for x in df.columns]\n",
    "\n",
    "# graph names\n",
    "def edit_graph_names(x):\n",
    "    x = x.replace(\"KEGG_\", \"\")\n",
    "    x = x.replace(\"_\", \" \")\n",
    "    x = x.capitalize()\n",
    "    return x\n",
    "\n",
    "graphs = [edit_graph_names(x) for x in graph_names]\n",
    "\n",
    "df = df.abs().T.groupby(df.columns).sum().T\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax = shap.summary_plot(df, feature_names=graphs, plot_type=\"bar\", show=False)\n",
    "plt.savefig(os.path.join(file_path, \"shap_kegg_summary.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Interpretation\n",
    "1. Compute SHAP values for a sample in the GCN model \n",
    "2. Visualize SHAP values to show pathway contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trainer.predict(shap_value_x[0:100])\n",
    "expected_values = pred.mean(0).to(\"cpu\").numpy()\n",
    "pred_label = np.argmax(pred, axis=1)\n",
    "y_label = dgl_dataset.y[sample][0:100]\n",
    "acc_pred = (y_label == pred_label)\n",
    "\n",
    "display_names = [x.replace('KEGG_', \"\").replace('_', \" \") for x in graph_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# force plot\n",
    "l = 0\n",
    "shap.force_plot(expected_values[l], shap_values[l],\n",
    "               feature_names = display_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "def plot_interpretation(i):\n",
    "    label_dict = {0: \"GCB\", 1:\"ABC\"}\n",
    "    print(f\"Predicted Label {i}: {label_dict[int(pred_label[i])]}\")\n",
    "    print(f\"Is the prediction correct?: {bool(acc_pred[i])}\")\n",
    "    l = int(pred_label[i]) # predicted label\n",
    "\n",
    "    aggregated_sv = np.array([shap_values[l][i][j*params[\"gcn_dim2\"]:(j+1)*params[\"gcn_dim2\"]].sum() for j in range(n_graph)]) # グラフ毎にまとめたShap values\n",
    "\n",
    "    ax = shap.force_plot(explainer.expected_value[l], aggregated_sv,\n",
    "                   feature_names = display_names,\n",
    "                   matplotlib=True, show=False,\n",
    "                    figsize=(16,5),text_rotation=0)\n",
    "    plt.subplots_adjust(top=0.50, bottom=0)\n",
    "    plt.savefig(\"tmp.png\")\n",
    "    plt.savefig(\"tmp.svg\")\n",
    "    plt.show()\n",
    "    \n",
    "    sv_dict = {}\n",
    "    for p_name, sv in zip(display_names, aggregated_sv):\n",
    "        sv_dict[p_name] = [sv]\n",
    "    df = pd.DataFrame(sv_dict).T.sort_values(by=0, ascending=False)\n",
    "    df = df.reset_index()\n",
    "    df.columns = [\"Pathway\", \"Shapley value\"]\n",
    "    #print(df)\n",
    "    return df\n",
    "\n",
    "df = plot_interpretation(0)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
